// App.js
import React, { useState } from 'react';
import { View, Text, Button, StyleSheet } from 'react-native';
import { Audio } from 'expo-av';
import { Deepgram } from '@deepgram/sdk';

export default function App() {
  const [recording, setRecording] = useState(null);
  const [transcription, setTranscription] = useState('');
  const [isRecording, setIsRecording] = useState(false);

  const deepgramApiKey = 'AIzaSyCaREgPQjYUsrzG9HR37FK63RhS6hy5SSw'; 
  const deepgram = new Deepgram(deepgramApiKey);

  const startRecording = async () => {
    try {
      console.log('Requesting permissions...');
      await Audio.requestPermissionsAsync();

      console.log('Starting recording...');
      const { recording } = await Audio.Recording.createAsync(
        Audio.RECORDING_OPTIONS_PRESET_HIGH_QUALITY
      );
      setRecording(recording);
      setIsRecording(true);
    } catch (err) {
      console.error('Failed to start recording', err);
    }
  };

  const stopRecording = async () => {
    console.log('Stopping recording...');
    setIsRecording(false);
    await recording.stopAndUnloadAsync();
    const uri = recording.getURI();
    setRecording(null);

    console.log('Recording stopped, sending audio to Deepgram...');
    const audioBuffer = await fetchAudioBuffer(uri);
    const transcriptionResult = await transcribeAudio(audioBuffer);
    setTranscription(transcriptionResult);
  };

  const fetchAudioBuffer = async (uri) => {
    const response = await fetch(uri);
    const blob = await response.blob();
    return blob;
  };

  const transcribeAudio = async (audioBuffer) => {
    try {
      const response = await deepgram.transcription.preRecorded(
        { buffer: audioBuffer, mimetype: 'audio/m4a' },
        { punctuate: true }
      );
      return response.results.channels[0].alternatives[0].transcript;
    } catch (error) {
      console.error('Error transcribing audio:', error);
      return 'Error during transcription.';
    }
  };

  return (
    <View style={styles.container}>
      <Text style={styles.title}>Voice Assistant</Text>
      <Button
        title={isRecording ? 'Stop Recording' : 'Start Recording'}
        onPress={isRecording ? stopRecording : startRecording}
      />
      {transcription ? (
        <View style={styles.transcriptionContainer}>
          <Text style={styles.transcriptionTitle}>Transcription:</Text>
          <Text style={styles.transcriptionText}>{transcription}</Text>
        </View>
      ) : null}
    </View>
  );
}

const styles = StyleSheet.create({
  container: {
    flex: 1,
    justifyContent: 'center',
    alignItems: 'center',
    padding: 20,
    backgroundColor: '#f5f5f5',
  },
  title: {
    fontSize: 24,
    fontWeight: 'bold',
    marginBottom: 20,
  },
  transcriptionContainer: {
    marginTop: 20,
    padding: 10,
    backgroundColor: '#fff',
    borderRadius: 10,
    elevation: 2,
    shadowColor: '#000',
    shadowOpacity: 0.1,
    shadowRadius: 5,
  },
  transcriptionTitle: {
    fontSize: 18,
    fontWeight: 'bold',
  },
  transcriptionText: {
    marginTop: 10,
    fontSize: 16,
  },
});
